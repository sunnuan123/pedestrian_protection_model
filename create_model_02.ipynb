{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "9f300c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import copy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from smt.surrogate_models import RBF,KRG,LS\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, Matern\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split, KFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR,NuSVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import plotly.colors as colors\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from pymoo.algorithms.soo.nonconvex.cmaes import CMAES\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.normalization import denormalize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from smt.surrogate_models import RBF,KRG,LS\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "# from smt.surrogate_models.rbf import RBF\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.algorithms.soo.nonconvex.de import DE\n",
    "from pymoo.problems import get_problem\n",
    "from pymoo.operators.sampling.lhs import LHS\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.algorithms.soo.nonconvex.isres import ISRES\n",
    "import warnings\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "89b6d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    '''读取数据'''\n",
    "    data1 = pd.read_csv('./data/data_1110.csv', na_values={'dist_out_in':0,'dist_out_mid':0,'dist_mid_in':0,'dist_in_hard':0})\n",
    "    data2 = pd.read_csv('./data/data_1205.csv',na_values={'dist_out_in':0,'dist_out_mid':0,'dist_mid_in':0,'dist_in_hard':0})\n",
    "    data = pd.concat([data1,data2], axis=0).iloc[:,1:].reset_index(drop=True)\n",
    "    return data.iloc[:,:-1], data['HIC15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f5d6008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData, rawLabel = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e8c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687cc591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955cff6b",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8b574",
   "metadata": {},
   "source": [
    "## 删除缺失率大于80%的数据列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0107b9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_mid_in     0.811798\n",
       "dist_out_mid    0.806180\n",
       "dist_in_hard    0.351124\n",
       "dist_out_in     0.199438\n",
       "T_out           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rawData.isnull().sum()/rawData.shape[0]).sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9d3c031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.drop(columns=['dist_mid_in','dist_out_mid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9010968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 56)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e69ab",
   "metadata": {},
   "source": [
    "## 均值填充缺失处理和方差筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ccac6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputerVar(data, threshold=1):\n",
    "    '''缺失处理和方差筛选'''\n",
    "    simpleImputer = SimpleImputer().fit(data)\n",
    "    joblib.dump(simpleImputer, './models/simpleImputer.pkl')\n",
    "    siData = simpleImputer.transform(data)\n",
    "    siData = pd.DataFrame(siData,columns=data.columns)\n",
    "    varModel = VarianceThreshold(threshold=threshold).fit(siData)\n",
    "#     print(data.shape)\n",
    "    print(set(varModel.feature_names_in_)-set(varModel.get_feature_names_out()))\n",
    "    siData = varModel.transform(siData)\n",
    "    siData = pd.DataFrame(siData, columns=varModel.get_feature_names_out())\n",
    "    inFeatures = siData.columns\n",
    "    return siData, inFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ec9f7ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'JL_X', 'T_S_mid_R', 'T_in', 'Y_S_out', 'head_V', 'Y_S_mid_F', 'delta_mid_R', 'T_S_mid_F', 'T_S_out', 'JR_Y', 'T_mid_R', 'delta_mid_F', 'Y_S_in', 'JR_Z', 'T_S_in', 'JR_X', 'Y_S_mid_R', 'JL_Y', 'delta_out', 'T_mid_F', 'T_out', 'delta_in'}\n"
     ]
    }
   ],
   "source": [
    "rawData, inFeatures = imputerVar(rawData, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "41e4dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 34)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176bd2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26945216",
   "metadata": {},
   "source": [
    "## 异常值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "56bee820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveoutliers(isExec, data, label, contamination):\n",
    "    '''是否处理异常值'''\n",
    "    def isoForest(data, label, flag, contamination=0.1):\n",
    "        '''孤立森林去除异常值'''\n",
    "        isoData = copy.deepcopy(data)\n",
    "        clf = IsolationForest(max_samples='auto', random_state=0, max_features=1,contamination=contamination).fit(isoData)\n",
    "        myIsoDataIndex = clf.predict(isoData)\n",
    "        print(Counter(myIsoDataIndex))\n",
    "#         print(myIsoDataIndex)\n",
    "        data_ = isoData[myIsoDataIndex==1]\n",
    "        label_ = label[myIsoDataIndex==1]\n",
    "        isoData = isoData[myIsoDataIndex==-1]\n",
    "        isoLabel = label[myIsoDataIndex==-1]\n",
    "        pd.concat([isoData,isoLabel], axis=1,ignore_index=True).to_csv('./data/significantSample.csv')\n",
    "        return data_, label_\n",
    "    if isExec:\n",
    "        return isoForest(data,label, contamination)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "ac705a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, label = solveoutliers(False, rawData, rawLabel, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937d653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "f764615c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point_X', 'point_Y', 'point_Z', 'bonnet_YL', 'bonnet_YR', 'bonnet_XF',\n",
       "       'bonnet_XR', 'bonnet_A', 'dist_out_in', 'dist_in_hard', 'Ixx', 'Iyy',\n",
       "       'Izz', 'head_A', 'head_M', 'JL_Z', 'LL_X', 'LL_Y', 'LL_Z', 'LR_X',\n",
       "       'LR_Y', 'LR_Z', 'B_LR_X', 'B_LR_Y', 'B_LR_Z', 'B_LF_X', 'B_LF_Y',\n",
       "       'B_LF_Z', 'B_RR_X', 'B_RR_Y', 'B_RR_Z', 'B_RF_X', 'B_RF_Y', 'B_RF_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a88b20e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356,)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08959793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc29e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02c37a8",
   "metadata": {},
   "source": [
    "# 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e82d02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdModel(data):\n",
    "    '''数据标准化，然后拆分数据集'''\n",
    "    stdModel = preprocessing.StandardScaler().fit(data)\n",
    "    stdData = stdModel.transform(data)\n",
    "    joblib.dump(stdModel,'./models/stdModel.pkl')\n",
    "    data = pd.DataFrame(stdData, columns=data.columns)\n",
    "    return data\n",
    "# data = stdModel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "00ba4dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 34)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3cf54924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point_X', 'point_Y', 'point_Z', 'bonnet_YL', 'bonnet_YR', 'bonnet_XF',\n",
       "       'bonnet_XR', 'bonnet_A', 'dist_out_in', 'dist_in_hard', 'Ixx', 'Iyy',\n",
       "       'Izz', 'head_A', 'head_M', 'JL_Z', 'LL_X', 'LL_Y', 'LL_Z', 'LR_X',\n",
       "       'LR_Y', 'LR_Z', 'B_LR_X', 'B_LR_Y', 'B_LR_Z', 'B_LF_X', 'B_LF_Y',\n",
       "       'B_LF_Z', 'B_RR_X', 'B_RR_Y', 'B_RR_Z', 'B_RF_X', 'B_RF_Y', 'B_RF_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = data.columns\n",
    "colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b08b4",
   "metadata": {},
   "source": [
    "# 数据拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80775e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4f1d50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(flag, label):\n",
    "    '''数据拆分'''\n",
    "#     data['label'] = rawLabel\n",
    "    xTrain,xTest,yTrain,yTest = train_test_split(data,label,test_size=0.1,random_state=420)\n",
    "    return xTrain,xTest,yTrain,yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "6de902d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain,xTest,yTrain,yTest = splitData(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d2fb21d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 34)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "faee393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 34)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8118235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point_X', 'point_Y', 'point_Z', 'bonnet_YL', 'bonnet_YR', 'bonnet_XF',\n",
       "       'bonnet_XR', 'bonnet_A', 'dist_out_in', 'dist_in_hard', 'Ixx', 'Iyy',\n",
       "       'Izz', 'head_A', 'head_M', 'JL_Z', 'LL_X', 'LL_Y', 'LL_Z', 'LR_X',\n",
       "       'LR_Y', 'LR_Z', 'B_LR_X', 'B_LR_Y', 'B_LR_Z', 'B_LF_X', 'B_LF_Y',\n",
       "       'B_LF_Z', 'B_RR_X', 'B_RR_Y', 'B_RR_Z', 'B_RF_X', 'B_RF_Y', 'B_RF_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee367a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7296cb16",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa2e33",
   "metadata": {},
   "source": [
    "## 线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "be7408a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLrModelSklearn():\n",
    "    model = LinearRegression()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    print(model.coef_)\n",
    "    joblib.dump(model, './models/lrModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ec3666c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:LinearRegression(),\n",
      "trainR2:0.849,\n",
      "testR2:0.845\n",
      "[ 1.91260510e+00 -2.48904533e-01 -2.26529386e+01 -7.54241606e-03\n",
      "  2.81824783e-02 -2.02609330e-02 -6.84957096e-02 -7.49758190e+00\n",
      " -1.69303263e+00 -8.36350074e-01  1.41466335e+02  1.30844493e+02\n",
      " -1.37909776e+02  1.68671438e+01  6.65590541e+01  6.12633090e+07\n",
      "  3.34800720e+09  2.42871445e+10  9.56007799e+08  3.34800720e+09\n",
      " -6.27086807e+09  9.56007799e+08 -4.67895605e+09 -3.00210567e+10\n",
      "  6.88860830e+08 -8.68685931e+09  2.00946867e+10  1.10670585e+09\n",
      "  8.53983176e+09  6.59006008e+09  4.34800467e+08 -4.43156739e+09\n",
      " -3.21142654e+09  7.36042467e+08]\n"
     ]
    }
   ],
   "source": [
    "lrMaeTestSklearn, lrMaeTrainSklearn, lrR2TrainSklearn, lrR2TestSklearn, lrModelSklearn, lryPredTestSklearn = createLrModelSklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e307d",
   "metadata": {},
   "source": [
    "# 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "072a5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSVRModelSklearn():\n",
    "    '''创建支持向量机回归模型'''\n",
    "    model = SVR()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/svrModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "27e86158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:SVR(),\n",
      "trainR2:-0.1,\n",
      "testR2:-0.094\n"
     ]
    }
   ],
   "source": [
    "svrMaeTestSklearn, svrMaeTrainSklearn, svrR2TrainSklearn, svrR2TestSklearn, svrModelSklearn, svryPredTestSklearn = createSVRModelSklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bab653",
   "metadata": {},
   "source": [
    "## 特征重要性函数编写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "926574c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesImportance(model, n, flag, colNames):\n",
    "    '''获取特征重要性排序,model:模型名字，n：过滤阈值，flag:模型名字，colNames，列名字'''\n",
    "    randomForestFeaturesImportance = dict(zip(colNames, model.feature_importances_))\n",
    "    sorted(randomForestFeaturesImportance.items(), key=lambda d: d[1], reverse=True)\n",
    "    randomForestFeaturesImportance = pd.DataFrame.from_dict(randomForestFeaturesImportance,orient='index') \\\n",
    "                                                            .rename(columns={'index':'featureName',0:'score'}) \\\n",
    "                                                            .sort_values(by='score', ascending=False)\n",
    "    randomForestFeaturesImportance = randomForestFeaturesImportance[randomForestFeaturesImportance['score']>n].reset_index()\n",
    "    randomForestFeaturesImportance.to_csv('./data/'+flag+'FeaturesImportance.csv', index=False)\n",
    "    return randomForestFeaturesImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d0501",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "888dd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomForestModelSklearn():\n",
    "    '''创建随机森林模型'''\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/randomForestModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5bfe160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:RandomForestRegressor(random_state=1),\n",
      "trainR2:0.98,\n",
      "testR2:0.909\n"
     ]
    }
   ],
   "source": [
    "randomForestMaeTestSklearn, randomForestMaeTrainSklearn, randomForestR2TrainSklearn, randomForestR2TestSklearn, randomForestModelSklearn, randomForestyPredTestSklearn = createRandomForestModelSklearn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "938c3524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomForestFeaturesImportance = getFeaturesImportance(randomForestModelSklearn,0.,'randomForest',colNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f1ce8",
   "metadata": {},
   "source": [
    "## XGB模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "15a7410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXgbModelSklearn():\n",
    "    '''创建XGB模型'''\n",
    "    model = XGBRegressor()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/xgbModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ee74883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...),\n",
      "trainR2:1.0,\n",
      "testR2:0.933\n"
     ]
    }
   ],
   "source": [
    "xgbMaeTestSklearn, xgbMaeTrainSklearn, xgbR2TrainSklearn, xgbR2TestSklearn, xgbModelSklearn, xgbyPredTestSklearn =createXgbModelSklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ccf2fbbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomForestFeaturesImportance = getFeaturesImportance(xgbModelSklearn,0.,'xgbModel',colNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d2d99",
   "metadata": {},
   "source": [
    "## CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7e1f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "dc600c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCatBoostModel():\n",
    "    '''创建CatBoost模型'''\n",
    "    # initialize Pool\n",
    "    trainPool = Pool(xTrain,\n",
    "                      yTrain)\n",
    "    testPool = Pool(xTest) \n",
    "\n",
    "    # specify the training parameters \n",
    "    model = CatBoostRegressor(silent=True)\n",
    "    #train the model\n",
    "    model.fit(trainPool)\n",
    "    # make the prediction using the resulting model\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/catBoostModel.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f5b50c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:<catboost.core.CatBoostRegressor object at 0x000001FECE470150>,\n",
      "trainR2:0.999,\n",
      "testR2:0.917\n"
     ]
    }
   ],
   "source": [
    "catBoostMaeTestSklearn, catBoostMaeTrainSklearn, catBoostR2TrainSklearn, catBoostR2TestSklearn, catBoostModelSklearn, catBoostyPredTestSklearn = createCatBoostModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e118342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "catBoostFeaturesImportance = getFeaturesImportance(catBoostModelSklearn,0.,'catBoost',colNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "97448604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point_X', 'point_Y', 'point_Z', 'bonnet_YL', 'bonnet_YR', 'bonnet_XF',\n",
       "       'bonnet_XR', 'bonnet_A', 'dist_out_in', 'dist_in_hard', 'Ixx', 'Iyy',\n",
       "       'Izz', 'head_A', 'head_M', 'JL_Z', 'LL_X', 'LL_Y', 'LL_Z', 'LR_X',\n",
       "       'LR_Y', 'LR_Z', 'B_LR_X', 'B_LR_Y', 'B_LR_Z', 'B_LF_X', 'B_LF_Y',\n",
       "       'B_LF_Z', 'B_RR_X', 'B_RR_Y', 'B_RR_Z', 'B_RF_X', 'B_RF_Y', 'B_RF_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd13dd7",
   "metadata": {},
   "source": [
    "# 加载所有模型并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8719e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别从F3取一个值，F2车型取两个值，用于测试\n",
    "predData = pd.read_csv('./data/preData2.csv')[colNames].values\n",
    "# 取F2数据预测\n",
    "# yPredData = pd.read_csv('./data/data_0104.csv', na_values={'dist_out_in':-1,'dist_out_mid':-1,'dist_mid_in':-1,'dist_in_hard':-1}).iloc[:,1:]['HIC15'].values\n",
    "# predData = pd.read_csv('./data/data_0104.csv', na_values={'dist_out_in':-1,'dist_out_mid':-1,'dist_mid_in':-1,'dist_in_hard':-1}).iloc[:,1:][colNames]\n",
    "# predData = SimpleImputer().fit_transform(predData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b48d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c0f2cd8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>线性回归</th>\n",
       "      <th>随机森林</th>\n",
       "      <th>支持向量机</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catBoost</th>\n",
       "      <th>真实值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364.977</td>\n",
       "      <td>486.852</td>\n",
       "      <td>730.627</td>\n",
       "      <td>483.415009</td>\n",
       "      <td>490.890</td>\n",
       "      <td>493.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>672.773</td>\n",
       "      <td>592.661</td>\n",
       "      <td>732.302</td>\n",
       "      <td>533.653992</td>\n",
       "      <td>601.623</td>\n",
       "      <td>635.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>756.133</td>\n",
       "      <td>816.896</td>\n",
       "      <td>732.339</td>\n",
       "      <td>748.197998</td>\n",
       "      <td>791.199</td>\n",
       "      <td>586.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>846.945</td>\n",
       "      <td>976.432</td>\n",
       "      <td>732.922</td>\n",
       "      <td>926.643982</td>\n",
       "      <td>926.366</td>\n",
       "      <td>1215.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415.453</td>\n",
       "      <td>555.304</td>\n",
       "      <td>730.775</td>\n",
       "      <td>565.078003</td>\n",
       "      <td>562.696</td>\n",
       "      <td>604.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      线性回归     随机森林    支持向量机     xgboost  catBoost      真实值\n",
       "0  364.977  486.852  730.627  483.415009   490.890   493.92\n",
       "1  672.773  592.661  732.302  533.653992   601.623   635.87\n",
       "2  756.133  816.896  732.339  748.197998   791.199   586.61\n",
       "3  846.945  976.432  732.922  926.643982   926.366  1215.94\n",
       "4  415.453  555.304  730.775  565.078003   562.696   604.13"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadModelAndPred(data,yTrue=None):\n",
    "    '''加载预测模型进行验证'''\n",
    "    lryPredSklearn = joblib.load('./models/lrModelSklearn.pkl').predict(data)\n",
    "    randomForestyPredSklearn = joblib.load('./models/randomForestModelSklearn.pkl').predict(data)\n",
    "    svryPredSklearn = joblib.load('./models/svrModelSklearn.pkl').predict(data)\n",
    "    xgbyPredSklearn = joblib.load('./models/xgbModelSklearn.pkl').predict(data)\n",
    "    catBoostyPred = joblib.load('./models/catBoostModel.pkl').predict(data)\n",
    "    # 收集预测结果形成csv文件\n",
    "    allModelPreds = {\n",
    "                    '线性回归':lryPredSklearn,\n",
    "                    '随机森林':randomForestyPredSklearn,\n",
    "                    '支持向量机':svryPredSklearn,\n",
    "                    'xgboost':xgbyPredSklearn,\n",
    "                    'catBoost':catBoostyPred\n",
    "    }\n",
    "    allModelPreds = pd.DataFrame(allModelPreds).round(3)\n",
    "    if yTrue is not None:\n",
    "        allModelPreds['真实值'] = yTrue\n",
    "        #  allModelPredsF2F3\n",
    "#         allModelPreds.to_csv('./data/allModelPredsF3.csv', encoding='gbk')\n",
    "        allModelPreds.to_csv('./data/allModelPredsF2F3.csv', encoding='gbk')\n",
    "    return allModelPreds\n",
    "# \n",
    "# allModelPreds = loadModelAndPred(predData)\n",
    "allModelPreds = loadModelAndPred(xTest.values,yTrue=yTest.values)\n",
    "allModelPreds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "2815a2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166180614791808"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(allModelPreds['真实值'], allModelPreds['catBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "78c05324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166180614791808"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(allModelPreds['真实值'], allModelPreds['catBoost'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91272f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f54b8992",
   "metadata": {},
   "source": [
    "# 求百分比1-abs(yTrue-yTest)/yTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7b7be208",
   "metadata": {},
   "outputs": [],
   "source": [
    "allModelPredsPercentage = pd.DataFrame()\n",
    "allModelPredsPercentage['xgboostPercent'] = 1- (allModelPreds['真实值'] - allModelPreds['xgboost']).abs()/allModelPreds['真实值']\n",
    "allModelPredsPercentage['catboostPercent'] = 1- (allModelPreds['真实值'] - allModelPreds['catBoost']).abs()/allModelPreds['真实值']\n",
    "allModelPredsPercentage.to_csv('./data/allModelPredsPercentF3.csv', encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499afbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f1505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60df97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8aa96bf7",
   "metadata": {},
   "source": [
    "## 求所有的R2数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7b3b15b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "modelname:LinearRegression(),\n",
      "trainR2:0.849,\n",
      "testR2:0.845\n",
      "[ 1.91260510e+00 -2.48904533e-01 -2.26529386e+01 -7.54241606e-03\n",
      "  2.81824783e-02 -2.02609330e-02 -6.84957096e-02 -7.49758190e+00\n",
      " -1.69303263e+00 -8.36350074e-01  1.41466335e+02  1.30844493e+02\n",
      " -1.37909776e+02  1.68671438e+01  6.65590541e+01  6.12633090e+07\n",
      "  3.34800720e+09  2.42871445e+10  9.56007799e+08  3.34800720e+09\n",
      " -6.27086807e+09  9.56007799e+08 -4.67895605e+09 -3.00210567e+10\n",
      "  6.88860830e+08 -8.68685931e+09  2.00946867e+10  1.10670585e+09\n",
      "  8.53983176e+09  6.59006008e+09  4.34800467e+08 -4.43156739e+09\n",
      " -3.21142654e+09  7.36042467e+08]\n",
      "******************************************************************************************\n",
      "modelname:SVR(),\n",
      "trainR2:-0.1,\n",
      "testR2:-0.094\n",
      "******************************************************************************************\n",
      "modelname:RandomForestRegressor(random_state=1),\n",
      "trainR2:0.98,\n",
      "testR2:0.909\n",
      "******************************************************************************************\n",
      "modelname:XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...),\n",
      "trainR2:1.0,\n",
      "testR2:0.933\n",
      "******************************************************************************************\n",
      "modelname:<catboost.core.CatBoostRegressor object at 0x000001FECFE2E710>,\n",
      "trainR2:0.999,\n",
      "testR2:0.917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      线性回归  支持向量机   随机森林  xgboost  catBoost\n",
       " 训练集  0.849 -0.100  0.980    1.000     0.999\n",
       " 测试集  0.845 -0.094  0.909    0.933     0.917,\n",
       "         线性回归    支持向量机    随机森林  xgboost  catBoost\n",
       " 训练集  129.955  320.261  34.725    0.116     9.089\n",
       " 测试集  131.690  288.860  89.173   71.550    79.820)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def createAllModel():\n",
    "    '''集中统一调用,\n",
    "    线性回归模型\t支持向量机模型\t随机森林模型\tXGB模型-->catBoost模型\n",
    "    '''\n",
    "    print('*'*90)\n",
    "    lrMaeTestSklearn, lrMaeTrainSklearn, lrR2TrainSklearn, lrR2TestSklearn, lrModelSklearn, lryPredTestSklearn = createLrModelSklearn()\n",
    "    print('*'*90)\n",
    "    svrMaeTestSklearn, svrMaeTrainSklearn, svrR2TrainSklearn, svrR2TestSklearn, svrModelSklearn, svryPredTestSklearn = createSVRModelSklearn()\n",
    "    print('*'*90)\n",
    "    randomForestMaeTestSklearn, randomForestMaeTrainSklearn, randomForestR2TrainSklearn, randomForestR2TestSklearn, randomForestModelSklearn, randomForestyPredTestSklearn = createRandomForestModelSklearn()\n",
    "    print('*'*90)\n",
    "    xgbMaeTestSklearn, xgbMaeTrainSklearn, xgbR2TrainSklearn, xgbR2TestSklearn, xgbModelSklearn, xgbyPredTestSklearn =createXgbModelSklearn()\n",
    "    print('*'*90)\n",
    "    catBoostMaeTestSklearn, catBoostMaeTrainSklearn, catBoostR2TrainSklearn, catBoostR2TestSklearn, catBoostModelSklearn, catBoostyPredTestSklearn = createCatBoostModel()    \n",
    "    allModelR2 = {\n",
    "                    '线性回归':[lrR2TrainSklearn, lrR2TestSklearn],\n",
    "                    '支持向量机':[svrR2TrainSklearn, svrR2TestSklearn],\n",
    "                    '随机森林':[randomForestR2TrainSklearn, randomForestR2TestSklearn],\n",
    "                    'xgboost':[xgbR2TrainSklearn, xgbR2TestSklearn],\n",
    "                    'catBoost':[catBoostR2TrainSklearn, catBoostR2TestSklearn]\n",
    "    }\n",
    "    allModelR2 = pd.DataFrame(allModelR2,index=['训练集', '测试集'])\n",
    "    allModelR2.to_csv('./data/allModelR2F3.csv', encoding='gbk')\n",
    "    allModelMae = {\n",
    "                    '线性回归':[lrMaeTrainSklearn, lrMaeTestSklearn],\n",
    "                    '支持向量机':[svrMaeTrainSklearn, svrMaeTestSklearn],\n",
    "                    '随机森林':[randomForestMaeTrainSklearn, randomForestMaeTestSklearn],\n",
    "                    'xgboost':[xgbMaeTrainSklearn, xgbMaeTestSklearn],\n",
    "                    'catBoost':[catBoostMaeTrainSklearn, catBoostMaeTestSklearn]\n",
    "    }\n",
    "    allModelMae = pd.DataFrame(allModelMae,index=['训练集', '测试集'])\n",
    "    allModelMae.to_csv('./data/allModelMaeF3.csv', encoding='gbk')\n",
    "    \n",
    "    return allModelR2, allModelMae\n",
    "createAllModel()    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d19444",
   "metadata": {},
   "source": [
    " ## 汇总模型所有特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "393a939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFeaturesImportance(colNames):\n",
    "    '''加载预测模型进行验证'''\n",
    "    randomForestyPredSklearn = joblib.load('./models/randomForestModelSklearn.pkl')\n",
    "    xgbyPredSklearn = joblib.load('./models/xgbModelSklearn.pkl')\n",
    "    catBoostyPred = joblib.load('./models/catBoostModel.pkl')\n",
    "    # 汇总模型所有特征重要性\n",
    "    randomForestFeaturesImportance = getFeaturesImportance(randomForestyPredSklearn, -1.,'randomForest',colNames)\n",
    "    xgbFeaturesImportance = getFeaturesImportance(xgbyPredSklearn, -1.,'xgboost',colNames)\n",
    "    catBoostFeaturesImportance = getFeaturesImportance(catBoostyPred, -1.,'catBoost',colNames)\n",
    "    allFeaturesImportance = pd.concat([randomForestFeaturesImportance,xgbFeaturesImportance,catBoostFeaturesImportance], axis=1)\n",
    "    return allFeaturesImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45164842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>point_Z</td>\n",
       "      <td>0.321181</td>\n",
       "      <td>Izz</td>\n",
       "      <td>0.330093</td>\n",
       "      <td>point_Z</td>\n",
       "      <td>22.675357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dist_in_hard</td>\n",
       "      <td>0.248033</td>\n",
       "      <td>point_Y</td>\n",
       "      <td>0.222342</td>\n",
       "      <td>dist_in_hard</td>\n",
       "      <td>21.198498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist_out_in</td>\n",
       "      <td>0.123188</td>\n",
       "      <td>dist_out_in</td>\n",
       "      <td>0.145209</td>\n",
       "      <td>dist_out_in</td>\n",
       "      <td>9.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bonnet_YR</td>\n",
       "      <td>0.051920</td>\n",
       "      <td>Ixx</td>\n",
       "      <td>0.079614</td>\n",
       "      <td>point_Y</td>\n",
       "      <td>6.551755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonnet_A</td>\n",
       "      <td>0.039960</td>\n",
       "      <td>bonnet_A</td>\n",
       "      <td>0.061903</td>\n",
       "      <td>bonnet_A</td>\n",
       "      <td>6.447501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Iyy</td>\n",
       "      <td>0.039758</td>\n",
       "      <td>Iyy</td>\n",
       "      <td>0.061554</td>\n",
       "      <td>bonnet_YL</td>\n",
       "      <td>5.751738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Izz</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>point_X</td>\n",
       "      <td>0.037464</td>\n",
       "      <td>Ixx</td>\n",
       "      <td>5.427982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bonnet_YL</td>\n",
       "      <td>0.035193</td>\n",
       "      <td>dist_in_hard</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>bonnet_YR</td>\n",
       "      <td>4.060978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bonnet_XR</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>bonnet_XR</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>Iyy</td>\n",
       "      <td>3.994834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>point_Y</td>\n",
       "      <td>0.030294</td>\n",
       "      <td>bonnet_YL</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>bonnet_XF</td>\n",
       "      <td>3.098667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ixx</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>bonnet_XF</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>point_X</td>\n",
       "      <td>2.932593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bonnet_XF</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>point_Z</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>Izz</td>\n",
       "      <td>2.755816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>head_A</td>\n",
       "      <td>0.004323</td>\n",
       "      <td>bonnet_YR</td>\n",
       "      <td>0.006745</td>\n",
       "      <td>bonnet_XR</td>\n",
       "      <td>1.805345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>point_X</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>LL_X</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>head_A</td>\n",
       "      <td>0.658069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>head_M</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>head_A</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>head_M</td>\n",
       "      <td>0.493106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LL_X</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>B_RR_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RF_X</td>\n",
       "      <td>0.425388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_RR_Z</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>B_LF_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RR_Z</td>\n",
       "      <td>0.376316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B_RF_Z</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>B_LF_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RF_Z</td>\n",
       "      <td>0.351726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B_LR_X</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>B_RR_X</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LR_Z</td>\n",
       "      <td>0.311181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B_RR_Y</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>B_RF_X</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LR_Y</td>\n",
       "      <td>0.219862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LR_X</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>B_RR_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LR_X</td>\n",
       "      <td>0.204701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LR_Y</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>B_RF_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LL_X</td>\n",
       "      <td>0.171420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B_LF_Y</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>B_LR_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LF_X</td>\n",
       "      <td>0.138443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B_RF_Y</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>B_LF_X</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RF_Y</td>\n",
       "      <td>0.138228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B_LF_Z</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>LL_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LL_Z</td>\n",
       "      <td>0.124513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B_RF_X</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>B_LR_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LF_Y</td>\n",
       "      <td>0.121768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B_LF_X</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>B_LR_X</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LR_Z</td>\n",
       "      <td>0.051856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LR_Z</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>LR_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LF_Z</td>\n",
       "      <td>0.049230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B_LR_Y</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>LR_Y</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LR_Y</td>\n",
       "      <td>0.048497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LL_Y</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>LR_X</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LL_Y</td>\n",
       "      <td>0.048245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LL_Z</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>LL_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>JL_Z</td>\n",
       "      <td>0.044860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>B_LR_Z</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>JL_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RR_X</td>\n",
       "      <td>0.042131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>B_RR_X</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>head_M</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RR_Y</td>\n",
       "      <td>0.033183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JL_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_RF_Z</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B_LR_X</td>\n",
       "      <td>0.032645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index     score         index     score         index      score\n",
       "0        point_Z  0.321181           Izz  0.330093       point_Z  22.675357\n",
       "1   dist_in_hard  0.248033       point_Y  0.222342  dist_in_hard  21.198498\n",
       "2    dist_out_in  0.123188   dist_out_in  0.145209   dist_out_in   9.213565\n",
       "3      bonnet_YR  0.051920           Ixx  0.079614       point_Y   6.551755\n",
       "4       bonnet_A  0.039960      bonnet_A  0.061903      bonnet_A   6.447501\n",
       "5            Iyy  0.039758           Iyy  0.061554     bonnet_YL   5.751738\n",
       "6            Izz  0.036942       point_X  0.037464           Ixx   5.427982\n",
       "7      bonnet_YL  0.035193  dist_in_hard  0.020897     bonnet_YR   4.060978\n",
       "8      bonnet_XR  0.033523     bonnet_XR  0.007697           Iyy   3.994834\n",
       "9        point_Y  0.030294     bonnet_YL  0.007635     bonnet_XF   3.098667\n",
       "10           Ixx  0.016260     bonnet_XF  0.007475       point_X   2.932593\n",
       "11     bonnet_XF  0.012488       point_Z  0.007089           Izz   2.755816\n",
       "12        head_A  0.004323     bonnet_YR  0.006745     bonnet_XR   1.805345\n",
       "13       point_X  0.003962          LL_X  0.002764        head_A   0.658069\n",
       "14        head_M  0.000413        head_A  0.001519        head_M   0.493106\n",
       "15          LL_X  0.000247        B_RR_Y  0.000000        B_RF_X   0.425388\n",
       "16        B_RR_Z  0.000228        B_LF_Y  0.000000        B_RR_Z   0.376316\n",
       "17        B_RF_Z  0.000204        B_LF_Z  0.000000        B_RF_Z   0.351726\n",
       "18        B_LR_X  0.000196        B_RR_X  0.000000        B_LR_Z   0.311181\n",
       "19        B_RR_Y  0.000194        B_RF_X  0.000000          LR_Y   0.219862\n",
       "20          LR_X  0.000176        B_RR_Z  0.000000          LR_X   0.204701\n",
       "21          LR_Y  0.000156        B_RF_Y  0.000000          LL_X   0.171420\n",
       "22        B_LF_Y  0.000154        B_LR_Z  0.000000        B_LF_X   0.138443\n",
       "23        B_RF_Y  0.000151        B_LF_X  0.000000        B_RF_Y   0.138228\n",
       "24        B_LF_Z  0.000133          LL_Y  0.000000          LL_Z   0.124513\n",
       "25        B_RF_X  0.000128        B_LR_Y  0.000000        B_LF_Y   0.121768\n",
       "26        B_LF_X  0.000117        B_LR_X  0.000000          LR_Z   0.051856\n",
       "27          LR_Z  0.000116          LR_Z  0.000000        B_LF_Z   0.049230\n",
       "28        B_LR_Y  0.000101          LR_Y  0.000000        B_LR_Y   0.048497\n",
       "29          LL_Y  0.000085          LR_X  0.000000          LL_Y   0.048245\n",
       "30          LL_Z  0.000064          LL_Z  0.000000          JL_Z   0.044860\n",
       "31        B_LR_Z  0.000064          JL_Z  0.000000        B_RR_X   0.042131\n",
       "32        B_RR_X  0.000048        head_M  0.000000        B_RR_Y   0.033183\n",
       "33          JL_Z  0.000000        B_RF_Z  0.000000        B_LR_X   0.032645"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAllFeaturesImportance(colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23669c10",
   "metadata": {},
   "source": [
    "# Optuna模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "5b09e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "4a2c240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "a852b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStudy(Objective, studyName):\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "        storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "        study_name=studyName,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(Objective, n_trials=10, timeout=600)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "22884181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbObjective(trial):\n",
    "    dtrain = lgb.Dataset(xTrain, label=yTrain)\n",
    "    dvalid = lgb.Dataset(xTest, label=yTest)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_iterations\":trial.suggest_int('num_iterations', 5, 20),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\",0.01, 0.1, step=0.01)\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "    gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])\n",
    "    \n",
    "    preds = gbm.predict(xTest)\n",
    "#     pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.r2_score(yTest, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "4f66fdda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-16 09:18:32,242] Using an existing study with name 'lgbModel' instead of creating a new one.\n",
      "[I 2024-01-16 09:18:32,770] Trial 62 finished with value: -0.09660984226137215 and parameters: {'num_iterations': 8, 'learning_rate': 0.02}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:33,108] Trial 63 finished with value: -0.05880308651323385 and parameters: {'num_iterations': 5, 'learning_rate': 0.04}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:33,447] Trial 64 finished with value: -0.0787230699653596 and parameters: {'num_iterations': 6, 'learning_rate': 0.03}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:33,922] Trial 65 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-01-16 09:18:34,247] Trial 66 finished with value: -0.16279747593898852 and parameters: {'num_iterations': 5, 'learning_rate': 0.02}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:34,589] Trial 67 finished with value: -0.0787230699653596 and parameters: {'num_iterations': 6, 'learning_rate': 0.03}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:34,929] Trial 68 finished with value: -0.13873998459136194 and parameters: {'num_iterations': 6, 'learning_rate': 0.02}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:35,278] Trial 69 finished with value: 0.011221245219010578 and parameters: {'num_iterations': 7, 'learning_rate': 0.04}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:35,579] Trial 70 finished with value: -0.16279747593898852 and parameters: {'num_iterations': 5, 'learning_rate': 0.02}. Best is trial 23 with value: -0.3130250037724056.\n",
      "[I 2024-01-16 09:18:35,970] Trial 71 finished with value: -0.04845648509524958 and parameters: {'num_iterations': 7, 'learning_rate': 0.03}. Best is trial 23 with value: -0.3130250037724056.\n"
     ]
    }
   ],
   "source": [
    "lgbStudy = createStudy(lgbObjective, 'lgbModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "ef50f084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_iterations': 6, 'learning_rate': 0.02}"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbStudy.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "7776d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbObjective(trial):\n",
    "#     data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "#     train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = xgb.DMatrix(xTrain, label=yTrain)\n",
    "    dvalid = xgb.DMatrix(xTest, label=yTest)\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-rmse\")\n",
    "    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")], callbacks=[pruning_callback])\n",
    "    \n",
    "    preds = bst.predict(dvalid)\n",
    "#     pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.r2_score(yTest, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3565ef42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:26,602] A new study created in RDB with name: xgbModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:253.93806\n",
      "[1]\tvalidation-rmse:231.54088\n",
      "[2]\tvalidation-rmse:224.59290\n",
      "[3]\tvalidation-rmse:221.49101\n",
      "[4]\tvalidation-rmse:219.29585\n",
      "[5]\tvalidation-rmse:217.97031\n",
      "[6]\tvalidation-rmse:215.58869\n",
      "[7]\tvalidation-rmse:214.07178\n",
      "[8]\tvalidation-rmse:212.38127\n",
      "[9]\tvalidation-rmse:210.33935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:27,224] Trial 0 finished with value: 0.6249155485128661 and parameters: {'booster': 'gblinear', 'lambda': 0.0006155564318973012, 'alpha': 1.77071686435378e-07}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.52479\n",
      "[1]\tvalidation-rmse:191.34167\n",
      "[2]\tvalidation-rmse:155.98354\n",
      "[3]\tvalidation-rmse:128.53757\n",
      "[4]\tvalidation-rmse:112.24430\n",
      "[5]\tvalidation-rmse:105.20590\n",
      "[6]\tvalidation-rmse:99.22480\n",
      "[7]\tvalidation-rmse:92.38507\n",
      "[8]\tvalidation-rmse:90.98924\n",
      "[9]\tvalidation-rmse:87.81237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:27,830] Trial 1 finished with value: 0.9346268654214207 and parameters: {'booster': 'dart', 'lambda': 0.0006440507553993703, 'alpha': 0.004619347374377372}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.43182\n",
      "[1]\tvalidation-rmse:230.30447\n",
      "[2]\tvalidation-rmse:224.29977\n",
      "[3]\tvalidation-rmse:221.82926\n",
      "[4]\tvalidation-rmse:219.24543\n",
      "[5]\tvalidation-rmse:216.95869\n",
      "[6]\tvalidation-rmse:215.65343\n",
      "[7]\tvalidation-rmse:213.09502\n",
      "[8]\tvalidation-rmse:212.35284\n",
      "[9]\tvalidation-rmse:209.14852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:28,398] Trial 2 finished with value: 0.6291505980925045 and parameters: {'booster': 'gblinear', 'lambda': 4.997040685255803e-07, 'alpha': 2.8483918709107956e-07}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.49884\n",
      "[1]\tvalidation-rmse:191.30962\n",
      "[2]\tvalidation-rmse:155.95894\n",
      "[3]\tvalidation-rmse:128.52998\n",
      "[4]\tvalidation-rmse:112.24824\n",
      "[5]\tvalidation-rmse:105.21331\n",
      "[6]\tvalidation-rmse:99.23627\n",
      "[7]\tvalidation-rmse:92.39858\n",
      "[8]\tvalidation-rmse:91.00401\n",
      "[9]\tvalidation-rmse:87.83031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:28,992] Trial 3 finished with value: 0.9346001520273776 and parameters: {'booster': 'dart', 'lambda': 2.85469785779718e-05, 'alpha': 2.1371407316372935e-06}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.49801\n",
      "[1]\tvalidation-rmse:191.31844\n",
      "[2]\tvalidation-rmse:155.97370\n",
      "[3]\tvalidation-rmse:128.53971\n",
      "[4]\tvalidation-rmse:112.25451\n",
      "[5]\tvalidation-rmse:105.21898\n",
      "[6]\tvalidation-rmse:99.24153\n",
      "[7]\tvalidation-rmse:92.40346\n",
      "[8]\tvalidation-rmse:91.00846\n",
      "[9]\tvalidation-rmse:87.83453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:29,592] Trial 4 finished with value: 0.9345938612918693 and parameters: {'booster': 'gbtree', 'lambda': 8.528933855762793e-06, 'alpha': 4.452048365748842e-05}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.52054\n",
      "[1]\tvalidation-rmse:191.33637\n",
      "[2]\tvalidation-rmse:155.97944\n",
      "[3]\tvalidation-rmse:128.53479\n",
      "[4]\tvalidation-rmse:112.24254\n",
      "[5]\tvalidation-rmse:105.20495\n",
      "[6]\tvalidation-rmse:99.22468\n",
      "[7]\tvalidation-rmse:92.38542\n",
      "[8]\tvalidation-rmse:90.99000\n",
      "[9]\tvalidation-rmse:87.81382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:30,192] Trial 5 finished with value: 0.9346246928159144 and parameters: {'booster': 'gbtree', 'lambda': 0.0005486767416600901, 'alpha': 2.3528990899815284e-08}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:247.15302\n",
      "[1]\tvalidation-rmse:187.50440\n",
      "[2]\tvalidation-rmse:145.50976\n",
      "[3]\tvalidation-rmse:123.23892\n",
      "[4]\tvalidation-rmse:106.94684\n",
      "[5]\tvalidation-rmse:98.89931\n",
      "[6]\tvalidation-rmse:93.18930\n",
      "[7]\tvalidation-rmse:89.84384\n",
      "[8]\tvalidation-rmse:87.02089\n",
      "[9]\tvalidation-rmse:86.32009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:30,820] Trial 6 finished with value: 0.9368298844364709 and parameters: {'booster': 'gbtree', 'lambda': 0.39001768308022033, 'alpha': 0.530953226900921}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.79970\n",
      "[1]\tvalidation-rmse:191.51724\n",
      "[2]\tvalidation-rmse:156.05811\n",
      "[3]\tvalidation-rmse:128.55446\n",
      "[4]\tvalidation-rmse:112.19540\n",
      "[5]\tvalidation-rmse:105.09565\n",
      "[6]\tvalidation-rmse:92.25154\n",
      "[7]\tvalidation-rmse:84.42007\n",
      "[8]\tvalidation-rmse:81.42497\n",
      "[9]\tvalidation-rmse:80.72137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:31,491] Trial 7 finished with value: 0.9447585563895793 and parameters: {'booster': 'gbtree', 'lambda': 0.0029775853025212607, 'alpha': 3.320625892007924e-05}. Best is trial 0 with value: 0.6249155485128661.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:259.14529\n",
      "[1]\tvalidation-rmse:238.36115\n",
      "[2]\tvalidation-rmse:229.93109\n",
      "[3]\tvalidation-rmse:225.05806\n",
      "[4]\tvalidation-rmse:221.90234\n",
      "[5]\tvalidation-rmse:219.64807\n",
      "[6]\tvalidation-rmse:218.14746\n",
      "[7]\tvalidation-rmse:216.88437\n",
      "[8]\tvalidation-rmse:215.47117\n",
      "[9]\tvalidation-rmse:214.34255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:32,120] Trial 8 finished with value: 0.6105024021138996 and parameters: {'booster': 'gblinear', 'lambda': 0.1881755597772026, 'alpha': 1.1755466083160747e-06}. Best is trial 8 with value: 0.6105024021138996.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:252.50752\n",
      "[1]\tvalidation-rmse:191.32033\n",
      "[2]\tvalidation-rmse:155.96714\n",
      "[3]\tvalidation-rmse:128.52672\n",
      "[4]\tvalidation-rmse:112.23790\n",
      "[5]\tvalidation-rmse:105.20272\n",
      "[6]\tvalidation-rmse:99.22513\n",
      "[7]\tvalidation-rmse:92.38742\n",
      "[8]\tvalidation-rmse:90.99309\n",
      "[9]\tvalidation-rmse:87.81888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 17:08:32,822] Trial 9 finished with value: 0.9346171631018271 and parameters: {'booster': 'gbtree', 'lambda': 0.00023641892308789696, 'alpha': 3.0118659882617117e-07}. Best is trial 8 with value: 0.6105024021138996.\n"
     ]
    }
   ],
   "source": [
    "xgbStudy = createStudy(xgbObjective, 'xgbModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b777ce96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 'gblinear',\n",
       " 'lambda': 0.1881755597772026,\n",
       " 'alpha': 1.1755466083160747e-06}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbStudy.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018f1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0676e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c96b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e6de8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
