{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9f300c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import copy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from smt.surrogate_models import RBF,KRG,LS\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, Matern\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split, KFold,GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR,NuSVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import plotly.colors as colors\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from pymoo.algorithms.soo.nonconvex.cmaes import CMAES\n",
    "from pymoo.termination import get_termination\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.core.problem import Problem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.util.normalization import denormalize\n",
    "from pymoo.visualization.scatter import Scatter\n",
    "from smt.surrogate_models import RBF,KRG,LS\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "# from smt.surrogate_models.rbf import RBF\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.algorithms.soo.nonconvex.de import DE\n",
    "from pymoo.problems import get_problem\n",
    "from pymoo.operators.sampling.lhs import LHS\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.algorithms.soo.nonconvex.isres import ISRES\n",
    "import warnings\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0de21655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(r'./data/data_1110.csv', na_values={'dist_out_in':0,'dist_out_mid':0,'dist_mid_in':0,'dist_in_hard':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "89b6d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    '''读取数据'''\n",
    "    data1 = pd.read_csv('./data/data_1110.csv', na_values={'dist_out_in':0,'dist_out_mid':0,'dist_mid_in':0,'dist_in_hard':0})\n",
    "    data2 = pd.read_csv('./data/data_1205.csv',na_values={'dist_out_in':0,'dist_out_mid':0,'dist_mid_in':0,'dist_in_hard':0})\n",
    "    data = pd.concat([data1,data2], axis=0).iloc[:,1:]\n",
    "    data['flag'] = ['F3' for i in range(data.shape[0])]\n",
    "    pdata = pd.read_csv('./data/data_0104.csv', na_values={'dist_out_in':-1,'dist_out_mid':-1,'dist_mid_in':-1,'dist_in_hard':-1}).iloc[:,1:]\n",
    "    pdata['flag'] = ['F2' for i in range(pdata.shape[0])]\n",
    "    rawData = pd.concat([data, pdata], axis=0).iloc[:,1:].reset_index(drop=True)\n",
    "    return rawData.iloc[:,:-2], rawData['HIC15'], rawData['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f5d6008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData, rawLabel, rawFlag = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "821e8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 57)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e499c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flag\n",
       "F3    356\n",
       "F2    181\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawFlag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9096d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "955cff6b",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c961c8e",
   "metadata": {},
   "source": [
    "## 删除缺失率大于80%的数据列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8b4392c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dist_mid_in     0.830540\n",
       "dist_out_mid    0.826816\n",
       "dist_in_hard    0.329609\n",
       "dist_out_in     0.214153\n",
       "Y_S_out         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rawData.isnull().sum()/rawData.shape[0]).sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6177b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.drop(columns=['dist_mid_in','dist_out_mid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "02959cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 55)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e69ab",
   "metadata": {},
   "source": [
    "## 均值填充缺失处理和方差筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ccac6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputerVar(data, threshold=1):\n",
    "    '''缺失处理和方差筛选'''\n",
    "    simpleImputer = SimpleImputer().fit(data)\n",
    "    joblib.dump(simpleImputer, './models/simpleImputer.pkl')\n",
    "    siData = simpleImputer.transform(data)\n",
    "    siData = pd.DataFrame(siData,columns=data.columns)\n",
    "    varModel = VarianceThreshold(threshold=threshold).fit(siData)\n",
    "#     print(data.shape)\n",
    "    print(set(varModel.feature_names_in_)-set(varModel.get_feature_names_out()))\n",
    "    siData = varModel.transform(siData)\n",
    "    siData = pd.DataFrame(siData, columns=varModel.get_feature_names_out())\n",
    "    inFeatures = siData.columns\n",
    "    return siData, inFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ec9f7ae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T_mid_R', 'JR_X', 'delta_in', 'T_S_out', 'T_S_mid_R', 'JR_Z', 'delta_out', 'Y_S_in', 'Y_S_out', 'JR_Y', 'delta_mid_F', 'T_S_in', 'delta_mid_R', 'T_S_mid_F', 'head_V', 'T_mid_F', 'Y_S_mid_R', 'T_in', 'T_out', 'Y_S_mid_F'}\n"
     ]
    }
   ],
   "source": [
    "rawData, inFeatures = imputerVar(rawData, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "41e4dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 35)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26945216",
   "metadata": {},
   "source": [
    "## 异常值检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "56bee820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveoutliers(isExec, data, label, flag, contamination):\n",
    "    '''是否处理异常值'''\n",
    "    def isoForest(data, label, flag, contamination=0.1):\n",
    "        '''孤立森林去除异常值'''\n",
    "        isoData = copy.deepcopy(data)\n",
    "        clf = IsolationForest(max_samples='auto', random_state=0, max_features=1,contamination=contamination).fit(isoData)\n",
    "        myIsoDataIndex = clf.predict(isoData)\n",
    "        print(Counter(myIsoDataIndex))\n",
    "#         print(myIsoDataIndex)\n",
    "        data_ = isoData[myIsoDataIndex==1]\n",
    "        label_ = label[myIsoDataIndex==1]\n",
    "        flag_ = flag[myIsoDataIndex==1]\n",
    "        isoData = isoData[myIsoDataIndex==-1]\n",
    "        isoLabel = label[myIsoDataIndex==-1]\n",
    "        isoFlag = flag[myIsoDataIndex==-1]\n",
    "        pd.concat([isoData,isoLabel,isoFlag], axis=1).to_csv('./data/significantSample.csv')\n",
    "        return data_, label_, flag_\n",
    "    if isExec:\n",
    "        return isoForest(data,label, flag, contamination)\n",
    "    return data, label, flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ac705a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, label, flag = solveoutliers(False, rawData, rawLabel, rawFlag, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9937d653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 35)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353565f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eebd9488",
   "metadata": {},
   "source": [
    "# 可视化分析训练数据测试数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "4b3419d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showVisual(data, label, flag ):\n",
    "    '''训练集和测试集数据可视化'''\n",
    "    columns = ['point_Z',\n",
    "             'point_Y',\n",
    "             'bonnet_YR',\n",
    "#              'Izz',\n",
    "#              'Ixx',\n",
    "             'Iyy'\n",
    "             ]\n",
    "    visData = copy.deepcopy(data[columns])\n",
    "    visData['label'] = label\n",
    "    visData['flag'] = flag\n",
    "    pp = sns.pairplot(visData, hue='flag',markers=[\"o\", \"s\"], corner=True, diag_kind=\"auto\",kind='reg')\n",
    "#     sns.pairplot(visData,hue='flag')\n",
    "    pp.fig.suptitle('The linear relationship between variables under different battery types')\n",
    "    # g.map_lower(sns.kdeplot, levels=4, color=\".2\")\n",
    "    plt.title('训练集和测试集之间关系图')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "dd69ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showVisual(data, label, flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "49ac57e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonnet_YR</th>\n",
       "      <th>point_Z</th>\n",
       "      <th>bonnet_YL</th>\n",
       "      <th>Iyy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flag</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>824.163473</td>\n",
       "      <td>825.491111</td>\n",
       "      <td>106.087513</td>\n",
       "      <td>20.766766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>799.769620</td>\n",
       "      <td>111.715113</td>\n",
       "      <td>800.556842</td>\n",
       "      <td>22.011294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bonnet_YR     point_Z   bonnet_YL        Iyy\n",
       "flag                                               \n",
       "F2    824.163473  825.491111  106.087513  20.766766\n",
       "F3    799.769620  111.715113  800.556842  22.011294"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(flag)[['bonnet_YR','point_Z','bonnet_YL','Iyy']].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f6c24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9d7eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ad84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87afdbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02c37a8",
   "metadata": {},
   "source": [
    "# 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e82d02ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdModel(data):\n",
    "    '''数据标准化，然后拆分数据集'''\n",
    "    stdModel = preprocessing.StandardScaler().fit(data)\n",
    "    stdData = stdModel.transform(data)\n",
    "    joblib.dump(stdModel,'./models/stdModel.pkl')\n",
    "    data = pd.DataFrame(stdData, columns=data.columns)\n",
    "    return data\n",
    "# data = stdModel(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "00ba4dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537, 35)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3cf54924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['point_Y', 'point_Z', 'bonnet_YL', 'bonnet_YR', 'bonnet_XF',\n",
       "       'bonnet_XR', 'bonnet_A', 'dist_out_in', 'dist_in_hard', 'Ixx', 'Iyy',\n",
       "       'Izz', 'head_A', 'head_M', 'JL_X', 'JL_Y', 'JL_Z', 'LL_X', 'LL_Y',\n",
       "       'LL_Z', 'LR_X', 'LR_Y', 'LR_Z', 'B_LR_X', 'B_LR_Y', 'B_LR_Z', 'B_LF_X',\n",
       "       'B_LF_Y', 'B_LF_Z', 'B_RR_X', 'B_RR_Y', 'B_RR_Z', 'B_RF_X', 'B_RF_Y',\n",
       "       'B_RF_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colNames = data.columns\n",
    "colNames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0b08b4",
   "metadata": {},
   "source": [
    "# 数据拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4f1d50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(flag, rawLabel):\n",
    "    '''数据拆分'''\n",
    "    data['label'] = rawLabel\n",
    "#     data['flag'] = flag\n",
    "    trainData = data[flag=='F3']\n",
    "    testData = data[flag=='F2']\n",
    "#     x_train,x_test,y_train,y_test = train_test_split(data,label,test_size=0.1,random_state=420)\n",
    "    yTrain = trainData.pop('label')\n",
    "    xTrain = trainData\n",
    "    yTest = testData.pop('label')\n",
    "    xTest = testData\n",
    "    return xTrain,xTest,yTrain,yTest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6de902d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain,xTest,yTrain,yTest = splitData(rawFlag, rawLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d2fb21d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356, 35)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296cb16",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa2e33",
   "metadata": {},
   "source": [
    "## 线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "be7408a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLrModelSklearn():\n",
    "    model = LinearRegression()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    print(model.coef_)\n",
    "    joblib.dump(model, './models/lrModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ec3666c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:LinearRegression(),\n",
      "trainR2:0.793,\n",
      "testR2:-1.3790121496140099e+18\n",
      "[-4.06484817e-01 -1.79974736e+01 -4.38218369e-02  2.77261348e-02\n",
      " -8.19182961e-02 -1.08224680e-01 -1.14263510e+01 -3.95862593e-01\n",
      " -1.00507005e+00  2.87280827e+02  2.65205277e+02 -2.81831590e+02\n",
      "  3.16758566e+01  7.31381103e+01 -2.59976192e+10 -1.23300674e+09\n",
      "  1.62047748e+07  5.70575870e+10  1.34147335e+11  8.94399631e+09\n",
      "  5.70575870e+10 -1.65042559e+10  8.94399631e+09 -8.45310646e+09\n",
      " -1.02204926e+11  9.66647241e+09  3.91109040e+10 -6.84165884e+10\n",
      "  1.84872031e+10 -8.86935442e+10  3.90636252e+10  6.09080198e+09\n",
      " -4.03358156e+10 -5.27672463e+10  1.51265142e+10]\n"
     ]
    }
   ],
   "source": [
    "lrMaeTestSklearn, lrMaeTrainSklearn, lrR2TrainSklearn, lrR2TestSklearn, lrModelSklearn, lryPredTestSklearn = createLrModelSklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17e307d",
   "metadata": {},
   "source": [
    "# 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "072a5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSVRModelSklearn():\n",
    "    '''创建支持向量机回归模型'''\n",
    "    model = SVR()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/svrModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "27e86158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:SVR(),\n",
      "trainR2:-0.104,\n",
      "testR2:-0.194\n"
     ]
    }
   ],
   "source": [
    "svrMaeTestSklearn, svrMaeTrainSklearn, svrR2TrainSklearn, svrR2TestSklearn, svrModelSklearn, svryPredTestSklearn = createSVRModelSklearn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bab653",
   "metadata": {},
   "source": [
    "## 特征重要性函数编写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "926574c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesImportance(model, n, flag, colNames):\n",
    "    '''获取特征重要性排序,model:模型名字，n：过滤阈值，flag:模型名字，colNames，列名字'''\n",
    "    randomForestFeaturesImportance = dict(zip(colNames, model.feature_importances_))\n",
    "    sorted(randomForestFeaturesImportance.items(), key=lambda d: d[1], reverse=True)\n",
    "    randomForestFeaturesImportance = pd.DataFrame.from_dict(randomForestFeaturesImportance,orient='index') \\\n",
    "                                                            .rename(columns={'index':'featureName',0:'score'}) \\\n",
    "                                                            .sort_values(by='score', ascending=False)\n",
    "    randomForestFeaturesImportance = randomForestFeaturesImportance[randomForestFeaturesImportance['score']>n].reset_index()\n",
    "    randomForestFeaturesImportance.to_csv('./data/'+flag+'FeaturesImportance.csv', index=False)\n",
    "    return randomForestFeaturesImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d0501",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "888dd720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRandomForestModelSklearn():\n",
    "    '''创建随机森林模型'''\n",
    "    model = RandomForestRegressor(random_state=1)\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/randomForestModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "5bfe160c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:RandomForestRegressor(random_state=1),\n",
      "trainR2:0.984,\n",
      "testR2:0.524\n"
     ]
    }
   ],
   "source": [
    "randomForestMaeTestSklearn, randomForestMaeTrainSklearn, randomForestR2TrainSklearn, randomForestR2TestSklearn, randomForestModelSklearn, randomForestyPredTestSklearn = createRandomForestModelSklearn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "938c3524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomForestFeaturesImportance = getFeaturesImportance(randomForestModelSklearn,0.,'randomForest',colNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f1ce8",
   "metadata": {},
   "source": [
    "## XGB模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "15a7410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXgbModelSklearn():\n",
    "    '''创建XGB模型'''\n",
    "    model = XGBRegressor()\n",
    "    model.fit(xTrain, yTrain)\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/xgbModelSklearn.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ee74883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...),\n",
      "trainR2:1.0,\n",
      "testR2:0.546\n"
     ]
    }
   ],
   "source": [
    "xgbMaeTestSklearn, xgbMaeTrainSklearn, xgbR2TrainSklearn, xgbR2TestSklearn, xgbModelSklearn, xgbyPredTestSklearn =createXgbModelSklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ccf2fbbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "randomForestFeaturesImportance = getFeaturesImportance(xgbModelSklearn,0.,'xgbModel',colNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5b5e0",
   "metadata": {},
   "source": [
    "## CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca312b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "cc1bb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCatBoostModel():\n",
    "    '''创建CatBoost模型'''\n",
    "    # initialize Pool\n",
    "    trainPool = Pool(xTrain,\n",
    "                      yTrain)\n",
    "    testPool = Pool(xTest) \n",
    "\n",
    "    # specify the training parameters \n",
    "    model = CatBoostRegressor(silent=True)\n",
    "    #train the model\n",
    "    model.fit(trainPool)\n",
    "    # make the prediction using the resulting model\n",
    "    yPredTest = model.predict(xTest)\n",
    "    yPredTrain = model.predict(xTrain)\n",
    "    r2Test = r2_score(yTest, yPredTest).round(3)\n",
    "    r2Train = r2_score(yTrain, yPredTrain).round(3)\n",
    "    maeTest = mean_absolute_error(yTest, yPredTest).round(3)\n",
    "    maeTrain = mean_absolute_error(yTrain, yPredTrain).round(3)\n",
    "    print(f'modelname:{model},\\ntrainR2:{r2Train},\\ntestR2:{r2Test}')\n",
    "    joblib.dump(model, './models/catBoostModel.pkl')\n",
    "    return maeTest, maeTrain,r2Train, r2Test, model, yPredTest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c68395f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelname:<catboost.core.CatBoostRegressor object at 0x0000028FBA544E90>,\n",
      "trainR2:0.999,\n",
      "testR2:0.484\n"
     ]
    }
   ],
   "source": [
    "catBoostMaeTestSklearn, catBoostMaeTrainSklearn, catBoostR2TrainSklearn, catBoostR2TestSklearn, catBoostModelSklearn, catBoostyPredTestSklearn = createCatBoostModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f3183c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "catBoostFeaturesImportance = getFeaturesImportance(catBoostModelSklearn,0.,'catBoost',colNames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1d804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13522738",
   "metadata": {},
   "source": [
    "# 加载所有模型并预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5f05936c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 35)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predData = pd.read_csv('./data/preData.csv')[colNames].values\n",
    "predData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1895046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c0f2cd8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>线性回归</th>\n",
       "      <th>随机森林</th>\n",
       "      <th>支持向量机</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>catBoost</th>\n",
       "      <th>真实值</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.658024e+11</td>\n",
       "      <td>779.699</td>\n",
       "      <td>728.841</td>\n",
       "      <td>551.940002</td>\n",
       "      <td>756.755</td>\n",
       "      <td>636.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-6.658024e+11</td>\n",
       "      <td>834.579</td>\n",
       "      <td>729.802</td>\n",
       "      <td>626.465027</td>\n",
       "      <td>800.761</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.658024e+11</td>\n",
       "      <td>830.809</td>\n",
       "      <td>729.547</td>\n",
       "      <td>678.497009</td>\n",
       "      <td>893.316</td>\n",
       "      <td>686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.658024e+11</td>\n",
       "      <td>789.890</td>\n",
       "      <td>729.223</td>\n",
       "      <td>544.500000</td>\n",
       "      <td>737.045</td>\n",
       "      <td>702.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.658024e+11</td>\n",
       "      <td>775.302</td>\n",
       "      <td>728.788</td>\n",
       "      <td>574.405029</td>\n",
       "      <td>875.731</td>\n",
       "      <td>746.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           线性回归     随机森林    支持向量机     xgboost  catBoost    真实值\n",
       "0 -6.658024e+11  779.699  728.841  551.940002   756.755  636.0\n",
       "1 -6.658024e+11  834.579  729.802  626.465027   800.761  644.0\n",
       "2 -6.658024e+11  830.809  729.547  678.497009   893.316  686.0\n",
       "3 -6.658024e+11  789.890  729.223  544.500000   737.045  702.0\n",
       "4 -6.658024e+11  775.302  728.788  574.405029   875.731  746.0"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadModelAndPred(data,yTrue=None):\n",
    "    '''加载预测模型进行验证'''\n",
    "    lryPredSklearn = joblib.load('./models/lrModelSklearn.pkl').predict(data)\n",
    "    randomForestyPredSklearn = joblib.load('./models/randomForestModelSklearn.pkl').predict(data)\n",
    "    svryPredSklearn = joblib.load('./models/svrModelSklearn.pkl').predict(data)\n",
    "    xgbyPredSklearn = joblib.load('./models/xgbModelSklearn.pkl').predict(data)\n",
    "    catBoostyPred = joblib.load('./models/catBoostModel.pkl').predict(data)\n",
    "    # 收集预测结果形成csv文件\n",
    "    allModelPreds = {\n",
    "                    '线性回归':lryPredSklearn,\n",
    "                    '随机森林':randomForestyPredSklearn,\n",
    "                    '支持向量机':svryPredSklearn,\n",
    "                    'xgboost':xgbyPredSklearn,\n",
    "                    'catBoost':catBoostyPred\n",
    "    }\n",
    "    allModelPreds = pd.DataFrame(allModelPreds).round(3)\n",
    "    if yTrue is not None:\n",
    "        allModelPreds['真实值'] = yTrue\n",
    "        allModelPreds.to_csv('./data/allModelPredsF2F3.csv', encoding='gbk')\n",
    "    return allModelPreds\n",
    "# \n",
    "# allModelPreds = loadModelAndPred(predData)\n",
    "allModelPreds = loadModelAndPred(xTest.values,yTrue=yTest.values)\n",
    "allModelPreds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00062901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db241d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7a0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09e05e54",
   "metadata": {},
   "source": [
    "# 求百分比1-abs(yTrue-yTest)/yTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "2b3af269",
   "metadata": {},
   "outputs": [],
   "source": [
    "allModelPredsPercentage = pd.DataFrame()\n",
    "allModelPredsPercentage['xgboostPercent'] = 1- (allModelPreds['真实值'] - allModelPreds['xgboost']).abs()/allModelPreds['真实值']\n",
    "allModelPredsPercentage['catboostPercent'] = 1- (allModelPreds['真实值'] - allModelPreds['catBoost']).abs()/allModelPreds['真实值']\n",
    "allModelPredsPercentage.to_csv('./data/allModelPredsPercentF2F3.csv', encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e15ad9a",
   "metadata": {},
   "source": [
    "## 求所有的R2数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "7b3b15b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "modelname:LinearRegression(),\n",
      "trainR2:0.793,\n",
      "testR2:-1.3790121496140099e+18\n",
      "[-4.06484817e-01 -1.79974736e+01 -4.38218369e-02  2.77261348e-02\n",
      " -8.19182961e-02 -1.08224680e-01 -1.14263510e+01 -3.95862593e-01\n",
      " -1.00507005e+00  2.87280827e+02  2.65205277e+02 -2.81831590e+02\n",
      "  3.16758566e+01  7.31381103e+01 -2.59976192e+10 -1.23300674e+09\n",
      "  1.62047748e+07  5.70575870e+10  1.34147335e+11  8.94399631e+09\n",
      "  5.70575870e+10 -1.65042559e+10  8.94399631e+09 -8.45310646e+09\n",
      " -1.02204926e+11  9.66647241e+09  3.91109040e+10 -6.84165884e+10\n",
      "  1.84872031e+10 -8.86935442e+10  3.90636252e+10  6.09080198e+09\n",
      " -4.03358156e+10 -5.27672463e+10  1.51265142e+10]\n",
      "******************************************************************************************\n",
      "modelname:SVR(),\n",
      "trainR2:-0.104,\n",
      "testR2:-0.194\n",
      "******************************************************************************************\n",
      "modelname:RandomForestRegressor(random_state=1),\n",
      "trainR2:0.984,\n",
      "testR2:0.524\n",
      "******************************************************************************************\n",
      "modelname:XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...),\n",
      "trainR2:1.0,\n",
      "testR2:0.546\n",
      "******************************************************************************************\n",
      "modelname:<catboost.core.CatBoostRegressor object at 0x0000028FA8595250>,\n",
      "trainR2:0.999,\n",
      "testR2:0.484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(             线性回归  支持向量机   随机森林  xgboost  catBoost\n",
       " 训练集  7.930000e-01 -0.104  0.984    1.000     0.999\n",
       " 测试集 -1.379012e+18 -0.194  0.524    0.546     0.484,\n",
       "              线性回归    支持向量机     随机森林  xgboost  catBoost\n",
       " 训练集  1.656050e+02  317.153   32.171    0.118     9.177\n",
       " 测试集  6.658024e+11  388.497  244.333  212.074   259.815)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def createAllModel():\n",
    "    '''集中统一调用,\n",
    "    线性回归模型\t支持向量机模型\t随机森林模型\tXGB模型-->catBoost模型\n",
    "    '''\n",
    "    print('*'*90)\n",
    "    lrMaeTestSklearn, lrMaeTrainSklearn, lrR2TrainSklearn, lrR2TestSklearn, lrModelSklearn, lryPredTestSklearn = createLrModelSklearn()\n",
    "    print('*'*90)\n",
    "    svrMaeTestSklearn, svrMaeTrainSklearn, svrR2TrainSklearn, svrR2TestSklearn, svrModelSklearn, svryPredTestSklearn = createSVRModelSklearn()\n",
    "    print('*'*90)\n",
    "    randomForestMaeTestSklearn, randomForestMaeTrainSklearn, randomForestR2TrainSklearn, randomForestR2TestSklearn, randomForestModelSklearn, randomForestyPredTestSklearn = createRandomForestModelSklearn()\n",
    "    print('*'*90)\n",
    "    xgbMaeTestSklearn, xgbMaeTrainSklearn, xgbR2TrainSklearn, xgbR2TestSklearn, xgbModelSklearn, xgbyPredTestSklearn =createXgbModelSklearn()\n",
    "    print('*'*90)\n",
    "    catBoostMaeTestSklearn, catBoostMaeTrainSklearn, catBoostR2TrainSklearn, catBoostR2TestSklearn, catBoostModelSklearn, catBoostyPredTestSklearn = createCatBoostModel()    \n",
    "    allModelR2 = {\n",
    "                    '线性回归':[lrR2TrainSklearn, lrR2TestSklearn],\n",
    "                    '支持向量机':[svrR2TrainSklearn, svrR2TestSklearn],\n",
    "                    '随机森林':[randomForestR2TrainSklearn, randomForestR2TestSklearn],\n",
    "                    'xgboost':[xgbR2TrainSklearn, xgbR2TestSklearn],\n",
    "                    'catBoost':[catBoostR2TrainSklearn, catBoostR2TestSklearn]\n",
    "    }\n",
    "    allModelR2 = pd.DataFrame(allModelR2,index=['训练集', '测试集'])\n",
    "    allModelR2.to_csv('./data/allModelR2F2F3.csv', encoding='gbk')\n",
    "    allModelMae = {\n",
    "                    '线性回归':[lrMaeTrainSklearn, lrMaeTestSklearn],\n",
    "                    '支持向量机':[svrMaeTrainSklearn, svrMaeTestSklearn],\n",
    "                    '随机森林':[randomForestMaeTrainSklearn, randomForestMaeTestSklearn],\n",
    "                    'xgboost':[xgbMaeTrainSklearn, xgbMaeTestSklearn],\n",
    "                    'catBoost':[catBoostMaeTrainSklearn, catBoostMaeTestSklearn]\n",
    "    }\n",
    "    allModelMae = pd.DataFrame(allModelMae,index=['训练集', '测试集'])\n",
    "    allModelMae.to_csv('./data/allModelMaeF2F3.csv', encoding='gbk')\n",
    "    \n",
    "    return allModelR2, allModelMae\n",
    "createAllModel()    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179b0ec",
   "metadata": {},
   "source": [
    " ## 汇总模型所有特征重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFeaturesImportance(colNames):\n",
    "    '''加载预测模型进行验证'''\n",
    "    randomForestyPredSklearn = joblib.load('./models/randomForestModelSklearn.pkl')\n",
    "    xgbyPredSklearn = joblib.load('./models/xgbModelSklearn.pkl')\n",
    "    catBoostyPred = joblib.load('./models/catBoostModel.pkl')\n",
    "    # 汇总模型所有特征重要性\n",
    "    randomForestFeaturesImportance = getFeaturesImportance(randomForestyPredSklearn, -1.,'randomForest',colNames)\n",
    "    xgbFeaturesImportance = getFeaturesImportance(xgbyPredSklearn, -1.,'xgboost',colNames)\n",
    "    catBoostFeaturesImportance = getFeaturesImportance(catBoostyPred, -1.,'catBoost',colNames)\n",
    "    allFeaturesImportance = pd.concat([randomForestFeaturesImportance,xgbFeaturesImportance,catBoostFeaturesImportance], axis=1)\n",
    "    return allFeaturesImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45164842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getAllFeaturesImportance(colNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23669c10",
   "metadata": {},
   "source": [
    "# Optuna模型调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5b09e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_rank\n",
    "from optuna.visualization import plot_slice\n",
    "from optuna.visualization import plot_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4a2c240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8a0f37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStudy(Objective, studyName):\n",
    "    study = optuna.create_study(\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=SEED),\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10),\n",
    "        storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "        study_name=studyName,\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(Objective, n_trials=10, timeout=600)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "22884181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbObjective(trial):\n",
    "    dtrain = lgb.Dataset(xTrain, label=yTrain)\n",
    "    dvalid = lgb.Dataset(xTest, label=yTest)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_iterations\":trial.suggest_int('num_iterations', 5, 20),\n",
    "        \"learning_rate\":trial.suggest_float(\"learning_rate\",0.01, 0.1, step=0.01)\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"rmse\")\n",
    "    gbm = lgb.train(param, dtrain, valid_sets=[dvalid], callbacks=[pruning_callback])\n",
    "    \n",
    "    preds = gbm.predict(xTest)\n",
    "#     pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.r2_score(yTest, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f2c511ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 15:01:19,684] Using an existing study with name 'lgbModel' instead of creating a new one.\n",
      "[I 2024-01-08 15:01:20,434] Trial 12 finished with value: -0.08197711719281431 and parameters: {'num_iterations': 20, 'learning_rate': 0.01}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:21,193] Trial 13 finished with value: -0.2574107579036913 and parameters: {'num_iterations': 20, 'learning_rate': 0.09999999999999999}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:21,946] Trial 14 finished with value: -0.2574107579036913 and parameters: {'num_iterations': 20, 'learning_rate': 0.09999999999999999}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:22,634] Trial 15 finished with value: -0.24691550782434035 and parameters: {'num_iterations': 18, 'learning_rate': 0.09999999999999999}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:23,324] Trial 16 finished with value: -0.19848651233388237 and parameters: {'num_iterations': 18, 'learning_rate': 0.060000000000000005}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:23,807] Trial 17 finished with value: -0.15210831750324716 and parameters: {'num_iterations': 11, 'learning_rate': 0.060000000000000005}. Best is trial 1 with value: -0.2574107579036913.\n",
      "[I 2024-01-08 15:01:24,611] Trial 18 finished with value: -0.2637342667999041 and parameters: {'num_iterations': 20, 'learning_rate': 0.08}. Best is trial 18 with value: -0.2637342667999041.\n",
      "[I 2024-01-08 15:01:25,256] Trial 19 finished with value: -0.12733950486240486 and parameters: {'num_iterations': 16, 'learning_rate': 0.03}. Best is trial 18 with value: -0.2637342667999041.\n",
      "[I 2024-01-08 15:01:26,017] Trial 20 finished with value: -0.24894834212901507 and parameters: {'num_iterations': 18, 'learning_rate': 0.08}. Best is trial 18 with value: -0.2637342667999041.\n",
      "[I 2024-01-08 15:01:26,725] Trial 21 finished with value: -0.1390919798959087 and parameters: {'num_iterations': 13, 'learning_rate': 0.04}. Best is trial 18 with value: -0.2637342667999041.\n"
     ]
    }
   ],
   "source": [
    "lgbStudy = createStudy(lgbObjective, 'lgbModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50f084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7776d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgbObjective(trial):\n",
    "#     data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "#     train_x, valid_x, train_y, valid_y = train_test_split(data, target, test_size=0.25)\n",
    "    dtrain = xgb.DMatrix(xTrain, label=yTrain)\n",
    "    dvalid = xgb.DMatrix(xTest, label=yTest)\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "    }\n",
    "    \n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-rmse\")\n",
    "    bst = xgb.train(param, dtrain, evals=[(dvalid, \"validation\")], callbacks=[pruning_callback])\n",
    "    \n",
    "    preds = bst.predict(dvalid)\n",
    "#     pred_labels = np.rint(preds)\n",
    "    accuracy = sklearn.metrics.r2_score(yTest, preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3565ef42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:25,487] Using an existing study with name 'xgbModel' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:567.96476\n",
      "[1]\tvalidation-rmse:581.46632\n",
      "[2]\tvalidation-rmse:579.29618\n",
      "[3]\tvalidation-rmse:585.16356\n",
      "[4]\tvalidation-rmse:597.88962\n",
      "[5]\tvalidation-rmse:602.37671\n",
      "[6]\tvalidation-rmse:602.28196\n",
      "[7]\tvalidation-rmse:606.36210\n",
      "[8]\tvalidation-rmse:607.67594\n",
      "[9]\tvalidation-rmse:610.76459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:26,163] Trial 100 finished with value: -0.1743087464455162 and parameters: {'booster': 'gbtree', 'lambda': 0.016050876683682797, 'alpha': 0.2435565924206753}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:565.55448\n",
      "[1]\tvalidation-rmse:567.68451\n",
      "[2]\tvalidation-rmse:572.77833\n",
      "[3]\tvalidation-rmse:589.33160\n",
      "[4]\tvalidation-rmse:595.40503\n",
      "[5]\tvalidation-rmse:606.67786\n",
      "[6]\tvalidation-rmse:614.45560\n",
      "[7]\tvalidation-rmse:621.36512\n",
      "[8]\tvalidation-rmse:630.22419\n",
      "[9]\tvalidation-rmse:637.49833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:26,779] Trial 101 finished with value: -0.27935978078979784 and parameters: {'booster': 'gbtree', 'lambda': 0.14879658889779085, 'alpha': 0.41953664007695696}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:570.12228\n",
      "[1]\tvalidation-rmse:570.53712\n",
      "[2]\tvalidation-rmse:575.87015\n",
      "[3]\tvalidation-rmse:585.80074\n",
      "[4]\tvalidation-rmse:589.06804\n",
      "[5]\tvalidation-rmse:590.22008\n",
      "[6]\tvalidation-rmse:593.34551\n",
      "[7]\tvalidation-rmse:600.87279\n",
      "[8]\tvalidation-rmse:604.73347\n",
      "[9]\tvalidation-rmse:607.95038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:27,437] Trial 102 finished with value: -0.16351198721361726 and parameters: {'booster': 'gbtree', 'lambda': 0.6857876097626645, 'alpha': 0.6678281500851827}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:565.02659\n",
      "[1]\tvalidation-rmse:572.85493\n",
      "[2]\tvalidation-rmse:571.53266\n",
      "[3]\tvalidation-rmse:580.98668\n",
      "[4]\tvalidation-rmse:588.51977\n",
      "[5]\tvalidation-rmse:594.62981\n",
      "[6]\tvalidation-rmse:604.39406\n",
      "[7]\tvalidation-rmse:612.81959\n",
      "[8]\tvalidation-rmse:614.76250\n",
      "[9]\tvalidation-rmse:625.70483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:28,335] Trial 103 finished with value: -0.23246220943987472 and parameters: {'booster': 'gbtree', 'lambda': 0.2916749556300587, 'alpha': 2.3545528113517726e-05}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:576.23373\n",
      "[1]\tvalidation-rmse:581.03534\n",
      "[2]\tvalidation-rmse:592.73065\n",
      "[3]\tvalidation-rmse:600.87529\n",
      "[4]\tvalidation-rmse:600.96288\n",
      "[5]\tvalidation-rmse:601.07916\n",
      "[6]\tvalidation-rmse:602.77872\n",
      "[7]\tvalidation-rmse:605.74808\n",
      "[8]\tvalidation-rmse:611.22765\n",
      "[9]\tvalidation-rmse:607.44781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:29,217] Trial 104 finished with value: -0.16158911537001486 and parameters: {'booster': 'gbtree', 'lambda': 0.08094176792044881, 'alpha': 7.16424843198329e-05}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:565.36050\n",
      "[1]\tvalidation-rmse:573.29097\n",
      "[2]\tvalidation-rmse:583.73018\n",
      "[3]\tvalidation-rmse:599.30683\n",
      "[4]\tvalidation-rmse:612.75527\n",
      "[5]\tvalidation-rmse:620.45572\n",
      "[6]\tvalidation-rmse:624.63716\n",
      "[7]\tvalidation-rmse:629.51310\n",
      "[8]\tvalidation-rmse:634.13992\n",
      "[9]\tvalidation-rmse:635.85320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:30,095] Trial 105 finished with value: -0.27276530422594125 and parameters: {'booster': 'gbtree', 'lambda': 0.1933962533060255, 'alpha': 0.05281697725718885}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:570.27562\n",
      "[1]\tvalidation-rmse:579.23927\n",
      "[2]\tvalidation-rmse:596.09158\n",
      "[3]\tvalidation-rmse:607.65751\n",
      "[4]\tvalidation-rmse:614.78306\n",
      "[5]\tvalidation-rmse:619.99204\n",
      "[6]\tvalidation-rmse:630.26693\n",
      "[7]\tvalidation-rmse:633.14516\n",
      "[8]\tvalidation-rmse:635.66465\n",
      "[9]\tvalidation-rmse:637.94002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:30,996] Trial 106 finished with value: -0.2811332508400095 and parameters: {'booster': 'gbtree', 'lambda': 0.5022423425170022, 'alpha': 0.29437257180578813}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:565.72073\n",
      "[1]\tvalidation-rmse:576.90289\n",
      "[2]\tvalidation-rmse:583.48666\n",
      "[3]\tvalidation-rmse:595.43733\n",
      "[4]\tvalidation-rmse:602.16647\n",
      "[5]\tvalidation-rmse:608.81626\n",
      "[6]\tvalidation-rmse:620.21201\n",
      "[7]\tvalidation-rmse:649.16024\n",
      "[8]\tvalidation-rmse:649.25225\n",
      "[9]\tvalidation-rmse:658.61610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:32,040] Trial 107 finished with value: -0.36552380226416026 and parameters: {'booster': 'gbtree', 'lambda': 0.11619881700677846, 'alpha': 3.4164085154724293e-06}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:565.67838\n",
      "[1]\tvalidation-rmse:575.89077\n",
      "[2]\tvalidation-rmse:585.16105\n",
      "[3]\tvalidation-rmse:598.60760\n",
      "[4]\tvalidation-rmse:607.73913\n",
      "[5]\tvalidation-rmse:609.91528\n",
      "[6]\tvalidation-rmse:613.57554\n",
      "[7]\tvalidation-rmse:615.16209\n",
      "[8]\tvalidation-rmse:618.30621\n",
      "[9]\tvalidation-rmse:624.26560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:32,850] Trial 108 finished with value: -0.22679898191926862 and parameters: {'booster': 'gbtree', 'lambda': 0.12422289780170334, 'alpha': 2.582283340560526e-06}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-rmse:567.96520\n",
      "[1]\tvalidation-rmse:581.43543\n",
      "[2]\tvalidation-rmse:579.24539\n",
      "[3]\tvalidation-rmse:585.08876\n",
      "[4]\tvalidation-rmse:597.76856\n",
      "[5]\tvalidation-rmse:602.35421\n",
      "[6]\tvalidation-rmse:602.24938\n",
      "[7]\tvalidation-rmse:606.27561\n",
      "[8]\tvalidation-rmse:607.58206\n",
      "[9]\tvalidation-rmse:610.66513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-08 14:51:33,624] Trial 109 finished with value: -0.17392632180384893 and parameters: {'booster': 'gbtree', 'lambda': 0.027242976417725107, 'alpha': 0.0021775336942768068}. Best is trial 72 with value: -0.39815368665345674.\n"
     ]
    }
   ],
   "source": [
    "xgbStudy = createStudy(xgbObjective, 'xgbModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbStudy.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7fa7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018f1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0676e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c96b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb02829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
